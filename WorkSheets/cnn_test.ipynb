{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d5b37f",
   "metadata": {},
   "source": [
    "# Test your CNN\n",
    "Here, we are going to test your CNN on data that it has never seen before. You will all test your CNN on the same dataset, so it will be a fair competition.\n",
    "\n",
    "The winner will be the CNN that produces the highest classification accuracy on the test set. In the unlikely situation that two or more CNNs have the same accuracy, then the winner will be the CNN that scores the lowest loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72832c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.79%   |   Loss: 0.2241\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Define the convolutional neural network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2) # 28 input, 28 output\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=4, padding=2, stride=2) # 28 input, 14 output\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 14 input, 14 output (+pool -> 7 output)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 7 input, 7 output (+pool -> 3 output)\n",
    "        self.conv5 = nn.Conv2d(128, 10, kernel_size=3, padding=0) # 3 input, 1 output (+pool -> 1 output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x)) # 28 input, 28 output\n",
    "        # x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x)) # 28 input, 14 output\n",
    "        # x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv3(x)) # 14 input, 14 output (+pool -> 7 output)\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv4(x)) # 7 input, 7 output (+pool -> 3 output)\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv5(x)) # 3 input, 1 output (+pool -> 1 output for each class) \n",
    "        x = x.squeeze(-1)  # Now shape is (batch_size, number of classes)\n",
    "        return x\n",
    "\n",
    "# Setup the loss\n",
    "criterion = nn.CrossEntropyLoss() # Loss function\n",
    "\n",
    "#Download and process the test dataset\n",
    "class PadTranslateCrop:\n",
    "    def __init__(self, pad, translate_px):\n",
    "        self.pad = pad\n",
    "        self.translate_px = translate_px\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Pad the image\n",
    "        img = transforms.functional.pad(img, self.pad, fill=0)\n",
    "        # Translate the image\n",
    "        dx = torch.randint(-self.translate_px, self.translate_px + 1, (1,)).item()\n",
    "        dy = torch.randint(-self.translate_px, self.translate_px + 1, (1,)).item()\n",
    "        img = transforms.functional.affine(img, angle=0, translate=(dx, dy), scale=1, shear=0, fill=0)\n",
    "        # Crop back to original size\n",
    "        w, h = img.size\n",
    "        left = (w - 28) // 2\n",
    "        top = (h - 28) // 2\n",
    "        img = transforms.functional.crop(img, top, left, 28, 28)\n",
    "        return img\n",
    "\n",
    "# Usage in your transform pipeline\n",
    "custom_transform = transforms.Compose([\n",
    "    PadTranslateCrop(pad=14, translate_px=10),  # pad and allow up to 10px translation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Download and prepare the training and test datasets\n",
    "data_test = datasets.MNIST(root='./data', train=False, download=True, transform=custom_transform)\n",
    "test_loader = DataLoader(data_test, batch_size=data_test.data.shape[0])\n",
    "# Get a batch of images and labels from the train_loader\n",
    "images, labels = next(iter(test_loader))\n",
    "# Load your CNN\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('./model_trained'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(images).squeeze(-1)\n",
    "    loss = criterion(outputs, labels)  # Calculate loss for the batch\n",
    "\n",
    "# Calculate classification accuracy\n",
    "_, predicted = torch.max(outputs, 1)  # Detach outputs before using for accuracy\n",
    "correct = (predicted == labels).sum().item() # Sum number of correct predictions\n",
    "accuracy = correct / labels.size(0) * 100.0 # Calculate percentage accuracy\n",
    "\n",
    "# Print the accuracy and loss\n",
    "print(f'Accuracy: {accuracy:.2f}%   |   Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
